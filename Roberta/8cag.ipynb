{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 899k/899k [00:01<00:00, 716kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:01<00:00, 387kB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:01<00:00, 690kB/s]\n",
      "Downloading: 100%|██████████| 688/688 [00:00<00:00, 233kB/s]\n",
      "Downloading: 100%|██████████| 1.43G/1.43G [02:09<00:00, 11.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"TODBERT/TOD-BERT-JNT-V1\")\n",
    "# tod_bert = AutoModel.from_pretrained(\"TODBERT/TOD-BERT-JNT-V1\")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-large-mnli\")\n",
    "bert = RobertaModel.from_pretrained(\"roberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>Was this a friend you were in love with， or ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>Where has she gone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sad</td>\n",
       "      <td>We no longer talk.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  context                                          utterance\n",
       "0     sad  I remember going to see the fireworks with my ...\n",
       "1     sad  Was this a friend you were in love with， or ju...\n",
       "2     sad                This was a best friend. I miss her.\n",
       "3     sad                                Where has she gone?\n",
       "4     sad                                 We no longer talk."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datapath = f'bbc-text.csv'\n",
    "datapath = f'train.csv'\n",
    "df = pd.read_csv('train.csv')\n",
    "val= pd.read_csv('8cag_valid.csv')\n",
    "test = pd.read_csv('8cag_test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='context'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEtCAYAAADqcgyMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAf3ElEQVR4nO3de5xdVX3+8c8DqSIqEGRETNBETfUHllZIAQFvYCGKEvQFFoqS0pT0gvdrsBf8obRYbRGsgiiBgChSrAKKxhhArMgl3G/apICS/ECiQUilXILP74+9DpxMzkwyc07O3tPzvF+veZ2z1977nO9kMvOcvfbaa8s2EREx2Daru4CIiKhfwiAiIhIGERGRMIiICBIGEREBTKq7gPHabrvtPG3atLrLiIiYUK677rpf2h4a3j5hw2DatGksXbq07jIiIiYUST/r1J5uooiISBhERETCICIiSBhERAQJg4iIIGEQEREkDCIigo0IA0kLJN0v6dYO6z4gyZK2K8uSdIqk5ZJulrRr27ZzJC0rX3Pa2neTdEvZ5xRJ6tU3FxERG2djjgzOAmYNb5S0I7A/8PO25jcAM8rXPODUsu22wHHAHsDuwHGSJpd9TgWObttvvfeKiIhNa4NXINu+QtK0DqtOAj4MXNjWNhs429Udc66StI2kHYDXAottrwaQtBiYJelyYCvbV5X2s4GDge+M9xuKiGiyafO/3fPXvPvEA7t+jXGdM5A0G1hp+6Zhq6YA97Qtryhto7Wv6NA+0vvOk7RU0tJVq1aNp/SIiOhgzGEgaUvgo8Df976c0dk+3fZM2zOHhtabZykiIsZpPEcGLwamAzdJuhuYClwv6XnASmDHtm2nlrbR2qd2aI+IiD4acxjYvsX2c21Psz2NqmtnV9v3ARcBR5ZRRXsCD9q+F1gE7C9pcjlxvD+wqKx7SNKeZRTRkax7DiIiIvpgY4aWfhX4MfBSSSskzR1l80uAO4HlwBeBvwYoJ44/Dlxbvo5vnUwu23yp7PNf5ORxRETfbcxoosM3sH5a23MDx4yw3QJgQYf2pcDLN1RHRERsOrkCOSIiEgYREZEwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERwUaEgaQFku6XdGtb26ck/UTSzZK+IWmbtnXHSlou6aeSDmhrn1Xalkua39Y+XdLVpf1rkp7Ww+8vIiI2wsYcGZwFzBrWthh4ue1dgP8EjgWQtBNwGLBz2efzkjaXtDnwOeANwE7A4WVbgE8CJ9l+CfAAMLer7ygiIsZsg2Fg+wpg9bC279leWxavAqaW57OB82w/avsuYDmwe/labvtO248B5wGzJQnYF7ig7L8QOLi7bykiIsaqF+cM/gz4Tnk+Bbinbd2K0jZS+3OAX7cFS6s9IiL6qKswkPQ3wFrg3N6Us8H3mydpqaSlq1at6sdbRkQMhHGHgaQ/Bd4EHGHbpXklsGPbZlNL20jtvwK2kTRpWHtHtk+3PdP2zKGhofGWHhERw4wrDCTNAj4MHGT74bZVFwGHSXq6pOnADOAa4FpgRhk59DSqk8wXlRC5DDik7D8HuHB830pERIzXxgwt/SrwY+ClklZImgv8K/BsYLGkGyWdBmD7NuB84Hbgu8Axtp8o5wTeCSwC7gDOL9sCfAR4v6TlVOcQzujpdxgRERs0aUMb2D68Q/OIf7BtnwCc0KH9EuCSDu13Uo02ioiImuQK5IiISBhERETCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiLYiHsgR8Rgmzb/2z1/zbtPPLDnrxndyZFBRERsOAwkLZB0v6Rb29q2lbRY0rLyOLm0S9IpkpZLulnSrm37zCnbL5M0p619N0m3lH1OkaRef5MRETG6jTkyOAuYNaxtPrDE9gxgSVkGeAMwo3zNA06FKjyA44A9gN2B41oBUrY5um2/4e8VERGb2AbPGdi+QtK0Yc2zgdeW5wuBy4GPlPazbRu4StI2knYo2y62vRpA0mJglqTLga1sX1XazwYOBr7TzTc1EaVfNiLqNN5zBtvbvrc8vw/YvjyfAtzTtt2K0jZa+4oO7R1JmidpqaSlq1atGmfpERExXNcnkMtRgHtQy8a81+m2Z9qeOTQ01I+3jIgYCOMNg1+U7h/K4/2lfSWwY9t2U0vbaO1TO7RHREQfjTcMLgJaI4LmABe2tR9ZRhXtCTxYupMWAftLmlxOHO8PLCrrHpK0ZxlFdGTba0VERJ9s8ASypK9SnQDeTtIKqlFBJwLnS5oL/Ax4W9n8EuCNwHLgYeAoANurJX0cuLZsd3zrZDLw11Qjlp5BdeJ44E4eR0TUbWNGEx0+wqr9Omxr4JgRXmcBsKBD+1Lg5RuqIyIiNp1cgRwREQmDiIhIGEREBAmDiIggYRAREQzA/Qwy5080Wa//f+b/ZoxXjgwiIiJhEBERA9BNFIMp3YMRY5Mjg4iISBhERETCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIugyDCS9T9Jtkm6V9FVJW0iaLulqScslfU3S08q2Ty/Ly8v6aW2vc2xp/6mkA7r8niIiYozGHQaSpgDvBmbafjmwOXAY8EngJNsvAR4A5pZd5gIPlPaTynZI2qnstzMwC/i8pM3HW1dERIxdt91Ek4BnSJoEbAncC+wLXFDWLwQOLs9nl2XK+v0kqbSfZ/tR23cBy4Hdu6wrIiLGYNxhYHsl8Gng51Qh8CBwHfBr22vLZiuAKeX5FOCesu/asv1z2ts77LMOSfMkLZW0dNWqVeMtPSIihummm2gy1af66cDzgWdSdfNsMrZPtz3T9syhoaFN+VYREQOlm26i1wN32V5l+3Hg34G9gW1KtxHAVGBleb4S2BGgrN8a+FV7e4d9IiKiD7oJg58De0rasvT97wfcDlwGHFK2mQNcWJ5fVJYp6y+17dJ+WBltNB2YAVzTRV0RETFG477tpe2rJV0AXA+sBW4ATge+DZwn6ROl7YyyyxnAOZKWA6upRhBh+zZJ51MFyVrgGNtPjLeuiIgYu67ugWz7OOC4Yc130mE0kO1HgENHeJ0TgBO6qSUiIsYvVyBHRETCICIiEgYREUHCICIiSBhERARdjiaKiGiKafO/3fPXvPvEA3v+mk2VI4OIiMiRQYxNPn1F/O+UI4OIiEgYREREwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIigyzCQtI2kCyT9RNIdkl4paVtJiyUtK4+Ty7aSdIqk5ZJulrRr2+vMKdsvkzSn228qIiLGptsjg5OB79p+GfD7wB3AfGCJ7RnAkrIM8AZgRvmaB5wKIGlb4DhgD2B34LhWgERERH+MOwwkbQ28GjgDwPZjtn8NzAYWls0WAgeX57OBs125CthG0g7AAcBi26ttPwAsBmaNt66IiBi7bo4MpgOrgDMl3SDpS5KeCWxv+96yzX3A9uX5FOCetv1XlLaR2tcjaZ6kpZKWrlq1qovSIyKiXTdhMAnYFTjV9iuA3/BUlxAAtg24i/dYh+3Tbc+0PXNoaKhXLxsRMfC6CYMVwArbV5flC6jC4Rel+4fyeH9ZvxLYsW3/qaVtpPaIiOiTcYeB7fuAeyS9tDTtB9wOXAS0RgTNAS4szy8CjiyjivYEHizdSYuA/SVNLieO9y9tERHRJ5O63P9dwLmSngbcCRxFFTDnS5oL/Ax4W9n2EuCNwHLg4bIttldL+jhwbdnueNuru6wrIiLGoKswsH0jMLPDqv06bGvgmBFeZwGwoJtaIiJi/HIFckREJAwiIiJhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigh6EgaTNJd0g6VtlebqkqyUtl/Q1SU8r7U8vy8vL+mltr3Fsaf+ppAO6rSkiIsamF0cG7wHuaFv+JHCS7ZcADwBzS/tc4IHSflLZDkk7AYcBOwOzgM9L2rwHdUVExEbqKgwkTQUOBL5UlgXsC1xQNlkIHFyezy7LlPX7le1nA+fZftT2XcByYPdu6oqIiLHp9sjgM8CHgd+W5ecAv7a9tiyvAKaU51OAewDK+gfL9k+2d9hnHZLmSVoqaemqVau6LD0iIlrGHQaS3gTcb/u6HtYzKtun255pe+bQ0FC/3jYi4n+9SV3suzdwkKQ3AlsAWwEnA9tImlQ+/U8FVpbtVwI7AiskTQK2Bn7V1t7Svk9ERPTBuI8MbB9re6rtaVQngC+1fQRwGXBI2WwOcGF5flFZpqy/1LZL+2FltNF0YAZwzXjrioiIsevmyGAkHwHOk/QJ4AbgjNJ+BnCOpOXAaqoAwfZtks4HbgfWAsfYfmIT1BURESPoSRjYvhy4vDy/kw6jgWw/Ahw6wv4nACf0opaIiBi7XIEcEREJg4iISBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIigizCQtKOkyyTdLuk2Se8p7dtKWixpWXmcXNol6RRJyyXdLGnXtteaU7ZfJmlO999WRESMRTdHBmuBD9jeCdgTOEbSTsB8YIntGcCSsgzwBmBG+ZoHnApVeADHAXsAuwPHtQIkIiL6Y9xhYPte29eX52uAO4ApwGxgYdlsIXBweT4bONuVq4BtJO0AHAAstr3a9gPAYmDWeOuKiIix68k5A0nTgFcAVwPb2763rLoP2L48nwLc07bbitI2UntERPRJ12Eg6VnA14H32n6ofZ1tA+72Pdrea56kpZKWrlq1qlcvGxEx8LoKA0m/QxUE59r+99L8i9L9Q3m8v7SvBHZs231qaRupfT22T7c90/bMoaGhbkqPiIg23YwmEnAGcIftf2lbdRHQGhE0B7iwrf3IMqpoT+DB0p20CNhf0uRy4nj/0hYREX0yqYt99wbeAdwi6cbS9lHgROB8SXOBnwFvK+suAd4ILAceBo4CsL1a0seBa8t2x9te3UVdERExRuMOA9v/AWiE1ft12N7AMSO81gJgwXhriYiI7uQK5IiISBhERETCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIigQWEgaZakn0paLml+3fVERAySRoSBpM2BzwFvAHYCDpe0U71VRUQMjkaEAbA7sNz2nbYfA84DZtdcU0TEwJDtumtA0iHALNt/XpbfAexh+53DtpsHzCuLLwV+2uNStgN+2ePX7LWJUCOkzl5Lnb01yHW+0PbQ8MZJPX6TTcr26cDpm+r1JS21PXNTvX4vTIQaIXX2WursrdS5vqZ0E60EdmxbnlraIiKiD5oSBtcCMyRNl/Q04DDgoppriogYGI3oJrK9VtI7gUXA5sAC27fVUMom64LqoYlQI6TOXkudvZU6h2nECeSIiKhXU7qJIiKiRgmDiIhIGERERMIgIiJoyGiifpP01tHW2/73ftWyMSS9C/iy7QfqrmU0kpbY3m9DbTE6SZ8FRhzZYfvdfSynI0m30LlGAba9S59LmtBG+fcEoB//ngMZBsCby+Nzgb2AS8vy64ArgUaFAbA9cK2k64EFwCI3aBiYpC2ALYHtJE2m+oMAsBUwpbbChpG0htF/4bbqYzmjWVoe96aauPFrZflQ4PZaKlrfm+ouYGNNkJ9769/zmPJ4Tnk8ol8FDPTQUknfA+bYvrcs7wCcZfuAeitbnyQB+wNHATOB84EzbP9XrYUBkt4DvBd4PtWV460weAj4ou1/ram0jiR9HLiX6hdOVL9wO9j++1oLG0bSVcA+tteW5d8Bfmh7z3orm5gmws9d0g22XzGs7Xrbu27q9x70cwY7toKg+AXwgrqKGU05ErivfK0FJgMXSPqnWgsDbJ9sezrwQdsvsj29fP1+04KgOMj2522vsf2Q7VNp5iy5k6mOrlqeVdoaQ9IaSQ+Vr0ckPSHpobrrGsFE+LlL0t5tC3vRp7/Tg9pN1LJE0iLgq2X5j4Hv11hPR+WT95FUsxd+CfiQ7cclbQYsAz5cZ30ttj9b/vNOo+3/lu2zayuqs99IOoJqqnQDhwO/qbekjk4EbpB0GdUn2VcDH6u1omFsP7v1vBy9zgaaeuQyEX7uc4EFkram+pk/APxZP954oLuJ4MmTya8qi1fY/kad9XQi6WPAmbZ/1mHd/7F9R/+rWp+kc4AXAzcCT5RmN+GEZztJ04CTqfrkDfwIeK/tu2ssqyNJzwP2KItX276vzno2RqeujiaYYD/3rQFsP9i39xz0MGi6che422y/rO5aNkTSHcBOTTq5PZGVT9pHAC+yfbykFwDPs31NzaU9adjIvM2ozme9xvYrayppwpN0ILAzsEWrzfbxm/p9B7KbSNJ/2N6nwyiD1rC4JowuAMD2E+Xe0C+w/fO669mAW4HnUZ2kayxJvwucCmxv++WSdqHqT/5EzaUN93ngt8C+wPHAGuDrwB/WWdQwb257vha4m+b1wwMg6Uw6jCqy3ZdumI0h6TSqkXmvo+oSPgToS/gPZBjY3qc8PntD2zbEZOA2SdfQ1sdp+6D6SupoO+D2UuejrcYG1vlF4EPAFwBs3yzpK0DTwmAP27tKugHA9gNlivfaSfqk7Y8A37F9ft31bKRvtT3fAngL8P9qqmUke9neRdLNtv+vpH8GvtOPNx7IMBhO0nNZ95CsaZ/A/67uAjbSx+ouYCNtafuaqhfmSWvrKmYUj5duQgNIGqI6UmiCN0qaD8ynGubceLa/3r4s6avAf9RUzkgeKY8PS3o+sBrYoR9vPNBhIOkg4J+pxsffD7wQuIOqv64xbP+g7ho2hu0fSHohMMP29yVtSXV/iqb5paQX89Qf2UNoZtfWKcA3gOdKOoGqy6ApHwy+SzXS5VnDhpI2rqt1FDOoLjxtkoslbQN8Crie6v/oF/vxxgN9AlnSTVT9sd+3/QpJrwPebntuzaWtY4QrKB+kulL1A7bv7H9V65N0NDAP2Nb2iyXNAE5r2nQUkl5EddOQvaj+oN0FHNFptFbdJL0M2I/qj+ySpowca5F0oe1GniMYru33SOXxPuDY4UcMdZJ0KPBd22sk/R2wK/Bx29dv6vce6CMD4HHbv5K0maTNbF8m6TN1F9XBZ4AVwFeo/iMfRjWEszU9xWvrKmyYY4DdgasBbC8rXXBNY9uvl/RMYLPyize97qKGk3SO7XcAP+nQ1ggTJQhgwpwj/Dvb/yZpH6oPqp+mGuywx+i7dW/Qr0D+taRnAVcA50o6meZdhALVSJcvtF05eTpwgO2v0awrUh+1/VhrQdIkRpkTpkZfB7D9G9trStsFNdYzknW6K8v5g91qqqUjSW+VtEzSg+Uq5DUNvgIZSQdJ+nT5auL8Sq3rcw6kmsrl20BfBg0M+pHBbOB/gPdRjefemmoIX9M8LOltPPUH6xCeOtHUpD+2P5D0UeAZkv4I+Gvg4pprelLpctkZ2HrY+PitaBtAUDdJxwKtf8eHeGqup8do3r17/wl4c9O6rzqRdCLVsNxzS9N7JO1l+6M1ljXcSklfAP4I+KSkp9OnD+0De86gfMr6vu3X1V3LhpQ+7pOBV1L98b+KKsBWArvZbsSIiDI9xlyqCfUELAK+1JSL0CTNBg4GDgIualu1BjjP9pV11DUSSf9o+9i66xiNpB/Z3nvDW9ZP0s3AH9j+bVneHLjBDZpuuwy6mAXcUrpZdwB+z/b3Nvl7N+T3tBaSlgBv7ecl31E/Sa+0/eO66xiJpJfZ/omkjjNV9uNk4oa0HVm9hupCw2+y7rUlTZsGvhUGr7W9uixvC1zepDCo06B3E/03cIukxax7MVfT5tIZAo5m/QngGnHlpBpwY44xeouk26i6CL8L7AK8z/aX6y3rSe+nGpX1zx3WmerEYt3arzx+mOposMU0754gAP/A+hP/za+3pOYY9CODOZ3abS/sdy2jkXQl8EPgOp46wbTeRTR1KdcWwPo35ng71cidRv3CSbrR9h9IegvVTUXeTzVJ4e/XXNqEI2lv2z/aUFvdShfmIVS/R63pPK6ZCBP/9ctAhoHKrRjbLqlvtNYfr7rr2JBOs1WqTzfmGAtJt9neWdKXgAtsf1fSTU0LA0nHAOfa/nVZngwcbvvztRbWptPPt4k/cwBJS23PrLuOphrUbqIdVM27f5Ck83hqtAbQjD7ZYb4l6Y22L6m7kA1Q+6dC9fHGHGN0saSfUHUT/VXphntkA/vU4Wjbn2stlLmJjqaawK5Wkl5JddHekKT3t63aimZedQ7wfUkfpLqNaHu38Or6SmqOQT0yOIRq1Ms+PHW/2RbbbkKf7JPKlZPPpDpB9zgNveRf0m5UF8Gtc2OOBoZr6+Thg2VW2C2BrZrWZVDOxezSGo1VRr/cbLv26VIkvYbqYse/BE5rW7UGuNj2sjrqGo2ku+g8a+mLaiincQYyDFrK5d7/Cvwu1ThzA9i+os66Oil/vGaw7oR6jZyzSDXcmGMsJB3Zqd0NuyObpE9RzZf1hdL0F8A9tj9QX1XrkvTCJk7j0YmkZ1Bd+7IP1e/6D6mmS/mfWgtriEEPg6OBdwNTqe7OtSdwZQPn0vlz4D00tE5Jb7f95WHdBU+y/S/9rmk0kj7btrgF1dw/19s+pKaSOionPecBry9Ni6mu23hi5L36Q9JnbL9X0sV0/rTdtGnLkXQ+8BBPXXT2J8DWtt9WX1XNMajnDFreTTWy4CrbrytXqP5DzTV18h6aXeeW5XEizP2C7Xe1L6uaJfK8eqoZ1ctsn0ZbN4yk1wKX11RPu9aIsU/XWsXYvNz2Tm3Ll0m6vbZqGmbQw+AR249IQtLTy4U+L627qA6aXueLy+Pttv+t1krG5zdA4yaqA86XdDbVdMZbUE39MJPqSvRa2b6uPDayq3IE10va0/ZVAJL2YP1zhgNr0MNgRflU+E1gsaQHgCb2fza9ztaNTo4FGh8Gw7o2NgN2opk3aNkD+CRwJdVR17lUN3NvDFXTlP8j1b9h+/msJp6U3Q24UlLr5lUvAH7aumiygRdH9tVAh4Htt5SnHytXJW5NdUVqo0yAOifajU7auzbWAj+zvaKuYkbxONXw12dQ/aG9qzWvToOcCRwHnER1396jaOZwYqjm/IkRDPQJ5OgtTaAbnUwEqm6+dCHVTLpDVOcOHrN9aK2FtZF0ne3dJN1i+/fa2+quLcamqQkeE9BECQKVOfeHfd0j6RtlhtimOBpYBnzU9r3Au4Cb6i1pPY+WUU/LJL2zTPHxrLqLirFLGETPaOLc6OQzwIeAKVTDdT9IdRe586gummuKo6iGER9eltdQ3YOjdpJao4m+STWa7N1UffLvADrO+RXNlm6i6BlJy5kANzrpNA9R2+R1jZmjqDXHT/ucT02Zp6oMyXw98B2qK5GHT+mSKR4mmIE+gRw994umB0ExUe4c93iZgqI1HcUQzanvNGAJ8CKq2XRbN5lvPTapuy02Qo4MomdU3UO68Tc60bp3jgP4Mc28c9wRwB8DuwILqULrb5t0LYekU23/Vd11RPcSBtEzks7s0Oym3IRnIipXm+9H9Yl7yQQ58ooJKGEQA0fSPwGfoLl3Oovou4wmip6RNLUMz7y/fH1d0tS66+pgf9sPUd3l7G7gJVSjiyIGVsIgeulM4CLg+eXr4tLWNK2BEwcC/9bUqbYj+ilhEL00ZPtM22vL11lUV842zbfKnc52A5Y0+E5nEX2TMIhe+pWkt0vavHy9HfhV3UUNZ3s+1S0bZ9p+nGrW0kZczBVRl5xAjp6R9ELgs1RDNk012+a7bN9Ta2GFpH1tXyrprZ3WN20IbEQ/5aKz6KXjgTm2H4Anb9X5aaApQ0tfDVwKvJl1L5BqPSYMYmAlDKKXdmkFAVRTEkh6RZ0FDbOm3JrzVp4KAWjOVb0RtUkYRC9tJmnysCODJv0fa82m+VKq24heSBUIbwauqauoiCbIOYPoGUlHAh/lqbudHQqcYPuckffqP0lXAAfaXlOWnw182/ar660soj5N+tQWE5ztsyUtBfYtTW+13cQbjm8PPNa2/FhpixhYCYPoqfLHv4kB0O5s4BpJ3yjLBwNn1VZNRAOkmygGkqRdgVeVxSts31BnPRF1SxhERESuQI6IiIRBRESQMIjoKUnTJP1JF/u/VtJevawpYmMkDCJ6axow7jCgurl8wiD6LmEQ0UbSkZJulnSTpHPKJ/1LS9sSSS8o250l6RRJV0q6U9Ih5SVOBF4l6UZJ7yuzt35K0rXlNf6i7P8+SQvK89+TdKuknYC/BN5X9n9VpxojNoVcZxBRSNoZ+FtgL9u/LNNpLAQW2l4o6c+AU6iuSwDYAdgHeBnVTX0uAOYDH7T9pvKa84AHbf+hpKcDP5L0PeBk4HJJbwH+BvgL27dLOg34b9uf7tO3HQHkyCCi3b5Udz77JVQT7VFNx/2Vsv4cqj/+Ld+0/dtyod1IVzDvDxwp6UbgauA5wAzbvwX+tLzmD2z/qMffS8SY5MggYvwebXuuEbYR1T0dFnVYNwP4b6pbhEbUKkcGEU+5FDhU0nPgyVlXrwQOK+uPAH64gddYAzy7bXkR8FeSfqe85u9Keqakram6nF4NPKftnMPw/SP6IkcGEYXt2ySdAPxA0hPADcC7gDMlfQhYBRy1gZe5GXhC0k1U8x2dTDXC6HpJKq9xMHAS8Dnb/ylpLnBZmU31YuACSbOpjig2FD4RPZHpKCIiIt1EERGRMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERwP8H1aHZ2V6e4LsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['context']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afraid' 'angry' 'confident' 'disgusted' 'excited' 'faithful' 'proud'\n",
      " 'sad']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['context'])\n",
    "c = list(le.classes_)\n",
    "labels={}\n",
    "for idx, la in enumerate(c):\n",
    "    labels.update({la:idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afraid': 0,\n",
       " 'angry': 1,\n",
       " 'confident': 2,\n",
       " 'disgusted': 3,\n",
       " 'excited': 4,\n",
       " 'faithful': 5,\n",
       " 'proud': 6,\n",
       " 'sad': 7}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = list(le.classes_)\n",
    "labels={}\n",
    "for idx, la in enumerate(c):\n",
    "    labels.update({la:idx})\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "# labels = {'afraid':0,\n",
    "#           'angry':1,\n",
    "#           'anxious':2,\n",
    "#           'disgusted':3,\n",
    "#           'embarrassed':4,\n",
    "#           'excited':5,\n",
    "#           'guilty':6,\n",
    "#           'jealous':7,\n",
    "#           'joyful':8,\n",
    "#           'lonely':9,\n",
    "#           'proud':10,\n",
    "#           'sad':11,\n",
    "#           'sentimental':12,\n",
    "#           'terrified':13,\n",
    "#           'trusting':14,\n",
    "#           }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [torch.tensor(labels[label], dtype=torch.long) for label in df['context']]\n",
    "        self.texts  = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['utterance']]\n",
    "        # self.story = torch.Tensor(tokenizer.convert_tokens_to_ids(self.texts)).long()\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.3):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(1024, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    #GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=4)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76622 6318 5701\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "# df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "#                                      [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df),len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9578 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.70 GiB total capacity; 21.30 GiB already allocated; 102.50 MiB free; 21.38 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-29c0fef7594a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-68402dd85069>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Liz/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-50fcd62981df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_id, mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdropout_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlinear_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Liz/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         )\n\u001b[0;32m--> 798\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    799\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Liz/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    496\u001b[0m                 )\n\u001b[1;32m    497\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    499\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Liz/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Liz/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     ):\n\u001b[0;32m--> 321\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Liz/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.70 GiB total capacity; 21.30 GiB already allocated; 102.50 MiB free; 21.38 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = Classifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df, val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.996\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text \n",
    "input_text = \"[CLS] [SYS] Hello, what can I help with you today? [USR] Find me a cheap restaurant nearby the north town.\"\n",
    "input_tokens = tokenizer.tokenize(input_text)\n",
    "story = torch.Tensor(tokenizer.convert_tokens_to_ids(input_tokens)).long()\n",
    "\n",
    "if len(story.size()) == 1: \n",
    "    story = story.unsqueeze(0) # batch size dimension\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    bert = bert.cuda()\n",
    "    story = story.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_context = {\"input_ids\": story, \"attention_mask\": (story > 0).long()}\n",
    "    hiddens = tod_bert(**input_context)[0] "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d4bfec3bdc190e8dff0dcb324e9700634d60a19f2b26054edea0e1e09d759a3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('Liz': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
