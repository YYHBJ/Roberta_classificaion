{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"TODBERT/TOD-BERT-JNT-V1\")\n",
    "# tod_bert = AutoModel.from_pretrained(\"TODBERT/TOD-BERT-JNT-V1\")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-large-mnli\")\n",
    "bert = RobertaModel.from_pretrained(\"roberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = f'bbc-text.csv'\n",
    "datapath = f'train.csv'\n",
    "df = pd.read_csv('train.csv')\n",
    "val= pd.read_csv('8cag_valid.csv')\n",
    "test = pd.read_csv('8cag_test.csv')\n",
    "df.head()\n",
    "df=df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='context'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['context']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['context'])\n",
    "c = list(le.classes_)\n",
    "labels={}\n",
    "for idx, la in enumerate(c):\n",
    "    labels.update({la:idx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afraid': 0,\n",
       " 'angry': 1,\n",
       " 'confident': 2,\n",
       " 'disgusted': 3,\n",
       " 'excited': 4,\n",
       " 'faithful': 5,\n",
       " 'proud': 6,\n",
       " 'sad': 7}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = list(le.classes_)\n",
    "labels={}\n",
    "for idx, la in enumerate(c):\n",
    "    labels.update({la:idx})\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "# labels = {'afraid':0,\n",
    "#           'angry':1,\n",
    "#           'anxious':2,\n",
    "#           'disgusted':3,\n",
    "#           'embarrassed':4,\n",
    "#           'excited':5,\n",
    "#           'guilty':6,\n",
    "#           'jealous':7,\n",
    "#           'joyful':8,\n",
    "#           'lonely':9,\n",
    "#           'proud':10,\n",
    "#           'sad':11,\n",
    "#           'sentimental':12,\n",
    "#           'terrified':13,\n",
    "#           'trusting':14,\n",
    "#           }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [torch.tensor(labels[label], dtype=torch.long) for label in df['context']]\n",
    "        self.texts  = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['utterance']]\n",
    "        # self.story = torch.Tensor(tokenizer.convert_tokens_to_ids(self.texts)).long()\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.3):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(1024, 8)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    #GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "    \n",
    "    torch.save(model,'models/model_roberta_1.pt')             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=4)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 5701\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "# df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "#                                      [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df),len(val[:100]), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.899 | Train Accuracy:  0.410 | Val Loss:  1.098 | Val Accuracy:  0.150\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "model = Classifier()\n",
    "LR = 1e-5\n",
    "              \n",
    "train(model, df, val[:100], LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('8cag_test.csv')\n",
    "# model = Classifier()\n",
    "model = torch.load('models/model_roberta_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.220\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text \n",
    "input_text = \"[CLS] [SYS] Hello, what can I help with you today? [USR] Find me a cheap restaurant nearby the north town.\"\n",
    "input_tokens = tokenizer.tokenize(input_text)\n",
    "story = torch.Tensor(tokenizer.convert_tokens_to_ids(input_tokens)).long()\n",
    "\n",
    "if len(story.size()) == 1: \n",
    "    story = story.unsqueeze(0) # batch size dimension\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    bert = bert.cuda()\n",
    "    story = story.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_context = {\"input_ids\": story, \"attention_mask\": (story > 0).long()}\n",
    "    hiddens = tod_bert(**input_context)[0] "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d4bfec3bdc190e8dff0dcb324e9700634d60a19f2b26054edea0e1e09d759a3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('Liz': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
